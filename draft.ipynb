{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>chroma_stft_var</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_centroid_var</th>\n",
       "      <th>spectral_bandwidth_mean</th>\n",
       "      <th>spectral_bandwidth_var</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>rolloff_var</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc16_var</th>\n",
       "      <th>mfcc17_mean</th>\n",
       "      <th>mfcc17_var</th>\n",
       "      <th>mfcc18_mean</th>\n",
       "      <th>mfcc18_var</th>\n",
       "      <th>mfcc19_mean</th>\n",
       "      <th>mfcc19_var</th>\n",
       "      <th>mfcc20_mean</th>\n",
       "      <th>mfcc20_var</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.335406</td>\n",
       "      <td>0.091048</td>\n",
       "      <td>0.130405</td>\n",
       "      <td>0.003521</td>\n",
       "      <td>1773.065032</td>\n",
       "      <td>167541.630869</td>\n",
       "      <td>1972.744388</td>\n",
       "      <td>117335.771563</td>\n",
       "      <td>3714.560359</td>\n",
       "      <td>1.080790e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>39.687145</td>\n",
       "      <td>-3.241280</td>\n",
       "      <td>36.488243</td>\n",
       "      <td>0.722209</td>\n",
       "      <td>38.099152</td>\n",
       "      <td>-5.050335</td>\n",
       "      <td>33.618073</td>\n",
       "      <td>-0.243027</td>\n",
       "      <td>43.771767</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.343065</td>\n",
       "      <td>0.086147</td>\n",
       "      <td>0.112699</td>\n",
       "      <td>0.001450</td>\n",
       "      <td>1816.693777</td>\n",
       "      <td>90525.690866</td>\n",
       "      <td>2010.051501</td>\n",
       "      <td>65671.875673</td>\n",
       "      <td>3869.682242</td>\n",
       "      <td>6.722448e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>64.748276</td>\n",
       "      <td>-6.055294</td>\n",
       "      <td>40.677654</td>\n",
       "      <td>0.159015</td>\n",
       "      <td>51.264091</td>\n",
       "      <td>-2.837699</td>\n",
       "      <td>97.030830</td>\n",
       "      <td>5.784063</td>\n",
       "      <td>59.943081</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.346815</td>\n",
       "      <td>0.092243</td>\n",
       "      <td>0.132003</td>\n",
       "      <td>0.004620</td>\n",
       "      <td>1788.539719</td>\n",
       "      <td>111407.437613</td>\n",
       "      <td>2084.565132</td>\n",
       "      <td>75124.921716</td>\n",
       "      <td>3997.639160</td>\n",
       "      <td>7.907127e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>67.336563</td>\n",
       "      <td>-1.768610</td>\n",
       "      <td>28.348579</td>\n",
       "      <td>2.378768</td>\n",
       "      <td>45.717648</td>\n",
       "      <td>-1.938424</td>\n",
       "      <td>53.050835</td>\n",
       "      <td>2.517375</td>\n",
       "      <td>33.105122</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.363639</td>\n",
       "      <td>0.086856</td>\n",
       "      <td>0.132565</td>\n",
       "      <td>0.002448</td>\n",
       "      <td>1655.289045</td>\n",
       "      <td>111952.284517</td>\n",
       "      <td>1960.039988</td>\n",
       "      <td>82913.639269</td>\n",
       "      <td>3568.300218</td>\n",
       "      <td>9.216524e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>47.739452</td>\n",
       "      <td>-3.841155</td>\n",
       "      <td>28.337118</td>\n",
       "      <td>1.218588</td>\n",
       "      <td>34.770935</td>\n",
       "      <td>-3.580352</td>\n",
       "      <td>50.836224</td>\n",
       "      <td>3.630866</td>\n",
       "      <td>32.023678</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.335579</td>\n",
       "      <td>0.088129</td>\n",
       "      <td>0.143289</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>1630.656199</td>\n",
       "      <td>79667.267654</td>\n",
       "      <td>1948.503884</td>\n",
       "      <td>60204.020268</td>\n",
       "      <td>3469.992864</td>\n",
       "      <td>6.102111e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>30.336359</td>\n",
       "      <td>0.664582</td>\n",
       "      <td>45.880913</td>\n",
       "      <td>1.689446</td>\n",
       "      <td>51.363583</td>\n",
       "      <td>-3.392489</td>\n",
       "      <td>26.738789</td>\n",
       "      <td>0.536961</td>\n",
       "      <td>29.146694</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   chroma_stft_mean  chroma_stft_var  rms_mean   rms_var   \n",
       "0          0.335406         0.091048  0.130405  0.003521  \\\n",
       "1          0.343065         0.086147  0.112699  0.001450   \n",
       "2          0.346815         0.092243  0.132003  0.004620   \n",
       "3          0.363639         0.086856  0.132565  0.002448   \n",
       "4          0.335579         0.088129  0.143289  0.001701   \n",
       "\n",
       "   spectral_centroid_mean  spectral_centroid_var  spectral_bandwidth_mean   \n",
       "0             1773.065032          167541.630869              1972.744388  \\\n",
       "1             1816.693777           90525.690866              2010.051501   \n",
       "2             1788.539719          111407.437613              2084.565132   \n",
       "3             1655.289045          111952.284517              1960.039988   \n",
       "4             1630.656199           79667.267654              1948.503884   \n",
       "\n",
       "   spectral_bandwidth_var  rolloff_mean   rolloff_var  ...  mfcc16_var   \n",
       "0           117335.771563   3714.560359  1.080790e+06  ...   39.687145  \\\n",
       "1            65671.875673   3869.682242  6.722448e+05  ...   64.748276   \n",
       "2            75124.921716   3997.639160  7.907127e+05  ...   67.336563   \n",
       "3            82913.639269   3568.300218  9.216524e+05  ...   47.739452   \n",
       "4            60204.020268   3469.992864  6.102111e+05  ...   30.336359   \n",
       "\n",
       "   mfcc17_mean  mfcc17_var  mfcc18_mean  mfcc18_var  mfcc19_mean  mfcc19_var   \n",
       "0    -3.241280   36.488243     0.722209   38.099152    -5.050335   33.618073  \\\n",
       "1    -6.055294   40.677654     0.159015   51.264091    -2.837699   97.030830   \n",
       "2    -1.768610   28.348579     2.378768   45.717648    -1.938424   53.050835   \n",
       "3    -3.841155   28.337118     1.218588   34.770935    -3.580352   50.836224   \n",
       "4     0.664582   45.880913     1.689446   51.363583    -3.392489   26.738789   \n",
       "\n",
       "   mfcc20_mean  mfcc20_var  label  \n",
       "0    -0.243027   43.771767  blues  \n",
       "1     5.784063   59.943081  blues  \n",
       "2     2.517375   33.105122  blues  \n",
       "3     3.630866   32.023678  blues  \n",
       "4     0.536961   29.146694  blues  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading data\n",
    "df_raw = pd.read_csv(\"Data/features_3_sec.csv\", sep=\",\")\n",
    "df_raw = df_raw.drop(columns='filename')\n",
    "df_raw = df_raw.drop(columns='length')\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz',\n",
       "       'metal', 'pop', 'reggae', 'rock'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_raw\n",
    "df_label = df.filter(regex=r'label')\n",
    "df_label['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.drop('label', axis=1)\n",
    "label_in_str = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6993, 57), (2997, 57), (6993,), (2997,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode target strings with values from 0 to n_classes - 1\n",
    "le = preprocessing.LabelEncoder()\n",
    "label = le.fit_transform(label_in_str)\n",
    "\n",
    "# Standardize feature values\n",
    "scalar = preprocessing.StandardScaler()\n",
    "scaled_data = scalar.fit_transform(data)\n",
    "\n",
    "# Train test split\n",
    "TEST_SIZE = 0.3\n",
    "RANDOM_STATE = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_data, label, test_size=TEST_SIZE, shuffle=True, random_state=RANDOM_STATE)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.955\n",
      "Test set score: 0.896\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.89       319\n",
      "           1       0.90      0.95      0.92       308\n",
      "           2       0.80      0.82      0.81       286\n",
      "           3       0.86      0.91      0.89       301\n",
      "           4       0.93      0.90      0.91       311\n",
      "           5       0.91      0.87      0.89       286\n",
      "           6       0.98      0.95      0.96       303\n",
      "           7       0.92      0.91      0.91       267\n",
      "           8       0.86      0.92      0.89       316\n",
      "           9       0.92      0.82      0.87       300\n",
      "\n",
      "    accuracy                           0.90      2997\n",
      "   macro avg       0.90      0.90      0.90      2997\n",
      "weighted avg       0.90      0.90      0.90      2997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_1 = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_1.fit(X_train, y_train)\n",
    "y_pred = knn_1.predict(X_test)\n",
    "print(\"Training set score: {:.3f}\".format(knn_1.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(knn_1.score(X_test, y_test)))\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.934\n",
      "Test set score: 0.885\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.89       319\n",
      "           1       0.87      0.95      0.91       308\n",
      "           2       0.80      0.85      0.82       286\n",
      "           3       0.82      0.90      0.86       301\n",
      "           4       0.93      0.90      0.91       311\n",
      "           5       0.90      0.84      0.86       286\n",
      "           6       0.98      0.94      0.96       303\n",
      "           7       0.91      0.90      0.90       267\n",
      "           8       0.85      0.91      0.87       316\n",
      "           9       0.92      0.79      0.85       300\n",
      "\n",
      "    accuracy                           0.89      2997\n",
      "   macro avg       0.89      0.88      0.88      2997\n",
      "weighted avg       0.89      0.89      0.89      2997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_2 = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_2.fit(X_train, y_train)\n",
    "y_pred = knn_2.predict(X_test)\n",
    "print(\"Training set score: {:.3f}\".format(knn_2.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(knn_2.score(X_test, y_test)))\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.915\n",
      "Test set score: 0.875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.86      0.88       319\n",
      "           1       0.87      0.97      0.92       308\n",
      "           2       0.77      0.83      0.80       286\n",
      "           3       0.81      0.91      0.86       301\n",
      "           4       0.94      0.88      0.91       311\n",
      "           5       0.89      0.84      0.87       286\n",
      "           6       0.95      0.92      0.94       303\n",
      "           7       0.91      0.91      0.91       267\n",
      "           8       0.83      0.88      0.86       316\n",
      "           9       0.91      0.75      0.82       300\n",
      "\n",
      "    accuracy                           0.87      2997\n",
      "   macro avg       0.88      0.87      0.87      2997\n",
      "weighted avg       0.88      0.87      0.87      2997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_3 = KNeighborsClassifier(n_neighbors=7)\n",
    "knn_3.fit(X_train, y_train)\n",
    "y_pred = knn_3.predict(X_test)\n",
    "print(\"Training set score: {:.3f}\".format(knn_3.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(knn_3.score(X_test, y_test)))\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.809\n",
      "Test set score: 0.763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.81      0.77       319\n",
      "           1       0.90      0.95      0.92       308\n",
      "           2       0.66      0.67      0.67       286\n",
      "           3       0.65      0.67      0.66       301\n",
      "           4       0.76      0.76      0.76       311\n",
      "           5       0.84      0.84      0.84       286\n",
      "           6       0.86      0.86      0.86       303\n",
      "           7       0.80      0.88      0.84       267\n",
      "           8       0.78      0.68      0.73       316\n",
      "           9       0.63      0.52      0.57       300\n",
      "\n",
      "    accuracy                           0.76      2997\n",
      "   macro avg       0.76      0.76      0.76      2997\n",
      "weighted avg       0.76      0.76      0.76      2997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_1 = SVC(kernel='linear')\n",
    "svm_1.fit(X_train, y_train)\n",
    "y_pred = svm_1.predict(X_test)\n",
    "print(\"Training set score: {:.3f}\".format(svm_1.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(svm_1.score(X_test, y_test)))\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.851\n",
      "Test set score: 0.781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.73      0.79       319\n",
      "           1       0.90      0.94      0.92       308\n",
      "           2       0.58      0.79      0.67       286\n",
      "           3       0.63      0.71      0.67       301\n",
      "           4       0.86      0.73      0.79       311\n",
      "           5       0.82      0.83      0.82       286\n",
      "           6       0.88      0.88      0.88       303\n",
      "           7       0.90      0.81      0.85       267\n",
      "           8       0.82      0.76      0.79       316\n",
      "           9       0.67      0.64      0.65       300\n",
      "\n",
      "    accuracy                           0.78      2997\n",
      "   macro avg       0.79      0.78      0.78      2997\n",
      "weighted avg       0.79      0.78      0.78      2997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_2 = SVC(kernel='poly', degree=2)\n",
    "svm_2.fit(X_train, y_train)\n",
    "y_pred = svm_2.predict(X_test)\n",
    "print(\"Training set score: {:.3f}\".format(svm_2.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(svm_2.score(X_test, y_test)))\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.913\n",
      "Test set score: 0.853\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87       319\n",
      "           1       0.85      0.98      0.91       308\n",
      "           2       0.79      0.79      0.79       286\n",
      "           3       0.81      0.80      0.80       301\n",
      "           4       0.93      0.84      0.88       311\n",
      "           5       0.84      0.85      0.85       286\n",
      "           6       0.89      0.92      0.91       303\n",
      "           7       0.87      0.90      0.88       267\n",
      "           8       0.88      0.87      0.88       316\n",
      "           9       0.78      0.69      0.73       300\n",
      "\n",
      "    accuracy                           0.85      2997\n",
      "   macro avg       0.85      0.85      0.85      2997\n",
      "weighted avg       0.85      0.85      0.85      2997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_3 = SVC(kernel='rbf')\n",
    "svm_3.fit(X_train, y_train)\n",
    "y_pred = svm_3.predict(X_test)\n",
    "print(\"Training set score: {:.3f}\".format(svm_3.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(svm_3.score(X_test, y_test)))\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henryhe/anaconda3/envs/COGS118ASp23/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn numpy array into pytorch tensor\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Create train and test datasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Put dataset into dataloader\n",
    "BATCH_SIZE = 256\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, output_size, device):\n",
    "        super(CNN, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.device = device\n",
    "\n",
    "        self.layer_1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.layer_2 = nn.Sequential(\n",
    "            nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.layer_3 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.fc_1 = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128*7, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "\n",
    "        self.fc_2 = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "\n",
    "        self.fc_3 = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "\n",
    "        self.fc_4 = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "\n",
    "        self.fc_5 = nn.Sequential(\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, output_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.layer_1(x)\n",
    "        x = self.layer_2(x)\n",
    "        x = self.layer_3(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc_1(x)\n",
    "        x = self.fc_2(x)\n",
    "        x = self.fc_3(x)\n",
    "        x = self.fc_4(x)\n",
    "        x = self.fc_5(x)\n",
    "        return nn.functional.softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "NUM_EPOCH = 500\n",
    "LEARNING_RATE = 0.0001\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(output_size=10, device=device).to(device)\n",
    "# Use sparse_softmax_cross_entropy\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/500 [00:01<15:41,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 2.3013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 11/500 [00:19<14:33,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Loss: 2.1700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 21/500 [00:37<14:16,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Loss: 2.0759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 23/500 [00:41<14:24,  1.81s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m X \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m----> 9\u001b[0m y_pred \u001b[39m=\u001b[39m model(X)\n\u001b[1;32m     10\u001b[0m l \u001b[39m=\u001b[39m loss(y_pred, y)\n\u001b[1;32m     11\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/envs/COGS118ASp23/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[39], line 63\u001b[0m, in \u001b[0;36mCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     61\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_1(x)\n\u001b[1;32m     62\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_2(x)\n\u001b[0;32m---> 63\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer_3(x)\n\u001b[1;32m     64\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflatten(x)\n\u001b[1;32m     65\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc_1(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/COGS118ASp23/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/COGS118ASp23/lib/python3.9/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/COGS118ASp23/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/COGS118ASp23/lib/python3.9/site-packages/torch/nn/modules/conv.py:307\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 307\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/anaconda3/envs/COGS118ASp23/lib/python3.9/site-packages/torch/nn/modules/conv.py:303\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    301\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    302\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 303\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    304\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42) \n",
    "torch.cuda.manual_seed(42)\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "for epoch in tqdm(range(NUM_EPOCH)):\n",
    "    for i, (X, y) in enumerate(train_loader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        y_pred = model(X)\n",
    "        l = loss(y_pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch}, Loss: {l.item():.4f}')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for X, y in test_loader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = model(X)\n",
    "            _, predicted = torch.max(y_pred.data, 1)\n",
    "            total += y.size(0)\n",
    "            correct += (predicted == y).sum().item()\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Accuracy of the network on the {total} test images: {100 * correct / total}%')\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "with torch.no_grad():\n",
    "    for X, y in test_loader:\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        y_pred.extend(torch.argmax(model(X), 1).tolist())\n",
    "        y_true.extend(y.tolist())\n",
    "\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(classification_report(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "COGS118ASp23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
